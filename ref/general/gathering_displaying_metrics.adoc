// Copyright (c) 2019 IBM Corporation and others.
// Licensed under Creative Commons Attribution-NoDerivatives
// 4.0 International (CC BY-ND 4.0)
//   https://creativecommons.org/licenses/by-nd/4.0/
//
// Contributors:
//     IBM Corporation
//
:page-description:
:seo-title:
:seo-description:
:page-layout: general-reference
:page-type: general
= Gathering and displaying Open Liberty metrics

:url-dashboard: https://grafana.com/dashboards/8022
:url-dashboard-github: https://github.com/Azquelt/microprofile-faulttolerance11-dashboard
:url-sample-app: https://github.com/Azquelt/faulttolerance-metrics-example
:url-ft11-spec: https://github.com/eclipse/microprofile-fault-tolerance/releases/tag/1.1.2
:url-ft11-spec-metrics: http://download.eclipse.org/microprofile/microprofile-fault-tolerance-1.1.2/microprofile-fault-tolerance-spec.html#_integration_with_microprofile_metrics
:url-rate: https://prometheus.io/docs/prometheus/latest/querying/functions/#rate()
:url-ol-download: https://openliberty.io/downloads/
:url-ol-ft-guide: https://github.com/OpenLiberty/iguide-retry-timeout/tree/master/finish
:url-prom-config: https://prometheus.io/docs/prometheus/latest/configuration/configuration/
:url-admin-role: https://openliberty.io/docs/ref/config/#rwlp_config_administrator-role.html
:url-7zip: https://www.7-zip.org/
:url-metrics11-spec: https://github.com/eclipse/microprofile-metrics/releases/tag/1.1.1
:url-prom-docs: https://prometheus.io/docs/introduction/overview/
:url-prom-ql: https://prometheus.io/docs/prometheus/latest/querying/basics/
:url-prom-best-practise: https://prometheus.io/docs/practices/naming/
:url-prom-alerts: https://prometheus.io/docs/alerting/overview/
:url-grafana-docs: http://docs.grafana.org/
:url-grafana-alerts: http://docs.grafana.org/alerting/rules/
:url-iguide-recover: https://openliberty.io/guides/retry-timeout.html
:url-iguide-limit: https://openliberty.io/guides/bulkhead.html
:url-guide-fallback: https://openliberty.io/guides/microprofile-fallback.html
:url-guide-circuitbreaker: https://openliberty.io/guides/circuit-breaker.html

After metrics are built into your application, you can gather the metric data by using Prometheus and display that data by creating graphs in Grafana.

The following steps use the fault tolerance metrics as an example to show you how to start working with your metric data. If you don't have your own app to work with, you can clone the {url-sample-app}[sample app], which uses MicroProfile Fault Tolerance and deploys to an Open Liberty server. The sample app includes the information from steps 1 - 3, so you can start gathering metrics by skipping to step 4 of the Gather metrics using Prometheus section.

== Gather metrics using Prometheus

. Configure your app to export metrics by adding the feature:mpMetrics-2.0[MicroProfile Metrics feature] in the `server.xml` file. You can also add features that allow extra metrics to be gathered. For example, if you want to gather fault tolerance metrics, add the `mpFaultTolerance-1.1` and `mpMetrics-1.1` features in the `server.xml` file:
+
[source,xml]
----
    <featureManager>
        <feature>mpFaultTolerance-1.1</feature>
        <feature>mpMetrics-1.1</feature>
        <!-- ... -->
    </featureManager>
----

. Ensure that a user has permission to access the metrics page. Include the following line in the `server.xml` file to create a user with admin access:
+
[source,xml]
----
    <quickStartSecurity userName="user" userPassword="password"/>
----
+
Alternatively, you can configure users on the server and use the {url-admin-role}[administrator-role] element to configure which users have admin access.

. Define an HTTPS port in the `<httpEndpoint>` section of the `server.xml` file:
+
[source, xml]
----
    <httpEndpoint id="defaultHttpEndpoint"
                  httpPort="9080"
                  httpsPort="9443"/>
----

. Run the app by using the `./gradlew libertyStart` command.
+
This command works because the `server.xml` file is configured to export metrics.

. Go to http://localhost:9080/ in your web browser and click a service to demonstrate a metric annotation.

. Go to https://localhost:9443/metrics, log in with your admin password, and see some basic server metrics.

. Now you need to install Prometheus and configure it to collect metrics from your Open Liberty server. https://prometheus.io/download/#prometheus[Download Prometheus] and extract it.

. Edit the prometheus.yml file. The scrape_configs section at the bottom of the file has one job that is configured for Prometheus. After that information, add the following new job information for Open Liberty:
+
[source, yaml]
----
  - job_name: 'openliberty'

    basic_auth:
      username: 'adminusername'
      password: 'adminpassword'

    scheme: 'https'

    tls_config:
            insecure_skip_verify: true

    static_configs:
            - targets: ['localhost:9443']

----
+
If you have a slightly different setup, check {url-prom-config}[Prometheus' configuration documentation] for the other options that can be specified.

. Now you can run the `./prometheus` command (or the `prometheus.exe` command on Windows), and you see logs that show that Prometheus is starting up. Go to http://localhost:9090/ to see the Prometheus web UI.

== Display metrics using Grafana

Although Prometheus has a basic web UI that can draw graphs from collected metrics, Grafana has some powerful features that can be used to display effective graphs. These features include the abilities to use placeholders in queries and collect several graphs into one shareable dashboard.

. link:https://grafana.com/grafana/download[Download Grafana].

. After you install or extract Grafana, start it by using the `bin/grafana-server` command, and go to the web UI in your browser. The default web UI is http://localhost:3000, the default log in user is `admin`, and the default log in password is `admin`.

. Import an existing dashboard to demonstrate the metrics in your app. Go to the Grafana dashboard page and follow the instructions to import the dashboard. Select which method to display metrics for by using the drop-down menu at the upper left of the dashboard. If you donâ€™t see any options here, hit the endpoints in your app. This calls the method and refreshes the dashboard page.

The following image shows the Grafana dashboard that displays a graph of invocations per second and failure rate from the fault tolerance metrics:

image::/docs/img/ftmetrics-imported-dashboard.png[The Grafana dashboard displaying a graph of the invocations per second and failure rate.]

This dashboard shows a selection of graphs for a single method at once. Because the dashboard shows only metrics for a single method, it isn't the best option to display an overview of the entire system. However, it does display all available details when you need to determine the cause of a problem.

== Create your own graphs

Let's take a quick look at how to create your own graphs. When you create your own graphs, you can extract metric data from several different methods and display it all on the same dashboard.

Metric names are passed to the MicroProfile Metrics API, which exports them in a format that conforms to {url-prom-best-practise}[Prometheus metrics best practices]. The MicroProfile Metrics API makes the following changes to metrics when they are exported to Prometheus:

* Metrics are put in the `application` namespace.
* Dots are replaced with underscores.
* `camelCase` words are separated by underscores.
* The entire name is converted to lowercase.
* Metrics that measure time are rescaled and reported in seconds, and `_seconds` is appended to the name.
* Histogram metrics are split into percentiles, limits, mean, and standard deviation.

For example, if you have the `callSlowService` method in the `com.example.TestService` class, which is annotated with the `@Timeout` fault tolerance annotation, you can query the following the metrics from Prometheus:

* Execution duration percentiles +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_seconds` +

* Minimum execution duration +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_min_seconds` +

* Maximum execution duration +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_max_seconds` +

* Mean execution duration +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_mean_seconds` +

* Standard deviation of execution durations +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_stddev_seconds` +

* The number of times the method was executed +
  `application:ft_com_example_test_service_call_slow_service_timeout_execution_duration_seconds_count` +

* The number of times the method timed out +
  `application:ft_com_example_test_service_call_slow_service_timeout_calls_timed_out_total` +

* The number of times the method completed without timing out +
  `application:ft_com_example_test_service_call_slow_service_timeout_calls_not_timed_out_total` +

// -

'''

Now, let's create graphs.

. In Grafana, create an empty dashboard:
+
image::/docs/img/ftmetrics-grafana-new-dashboard.png[Screenshot of Grafana highlighting the new dashboard button on the left sidebar menu]

. Add a new panel and choose Graph as the new panel type:
+
image::/docs/img/ftmetrics-grafana-new-graph.png[Screenshot of Grafana highlighting the new panel button and the graph button]

. Click Edit from the panel header menu:
+
image::/docs/img/ftmetrics-grafana-edit-graph.png[Screenshot of Grafana with the menu of the new panel open highlighting the edit button]

. Select the Metrics tab. You can write a query using {url-prom-ql}[Prometheus Query Language] in the query field:
+
image::/docs/img/ftmetrics-grafana-metrics-tab.png[Screenshot of Grafana showing the graph editing screen with the metrics tab open]

Now you have a new empty graph. You can graph the total number of calls to a particular method. For example, graph the total number of calls to the `callSlowService` method by using the following query:

----
application:ft_com_example_test_service_call_slow_service_invocations_total
----

Load the page to generate traffic, and Grafana displays a graph of the number of times the method was called. A graph of the sample app looks similar to this example:

image::/docs/img/ftmetrics-invocations-graph.png[Screenshot of Grafana showing the graph editing screen. The query from above has been entered in the query box. A line graph is above it with the line moving unevenly up and to the right.]

You can see that the graph trends upward as more requests are served.

You can also track the rate of requests by using the `{url-rate}[rate]` query. For example, graph the rate of requests to the `callSlowService` method by using the following query:

----
rate(application:ft_com_example_test_service_call_slow_service_invocations_total[1m])
----

The rate is calculated by averaging the total number of invocations over the preceding minute. The following example displays how many requests the `callSlowService` method receives per second:

image::/docs/img/ftmetrics-invocations-rate-graph.png[Screenshot of Grafana showing the graph editing screen. The query from above has been entered in the query box. A line graph is above it. The line on the graph goes up and down over time, ranging between 0 and 1.2 requests per second.]

Prometheus best practices recommend using counter metrics to gather your metric data. They are lightweight, flexible for graphing, and they cope gracefully with missing samples or server restarts. Prometheus stores the value of counter metrics at set intervals and can retrospectively process these values to calculate rates of change, moving averages, or ratios.

Use fault tolerance metrics in a more complex query to graph the percentage of calls that timed out, averaged over the last minute. To display this information, divide the number of calls that timed out by the total number of calls to determine the percentage of calls that timed out. Then, average that percentage over the last minute:

----
rate(application:ft_com_example_test_service_call_slow_service_timeout_calls_timed_out_total[1m]) * 100
/
(
   rate(application:ft_com_example_test_service_call_slow_service_timeout_calls_timed_out_total[1m])
 + rate(application:ft_com_example_test_service_call_slow_service_timeout_calls_not_timed_out_total[1m])
)
----

image::/docs/img/ftmetrics-timeout-percentage-graph.png[Screenshot of Grafana showing the graph editing screen. The query from above has been entered in the query box. A line graph is above it. The line graph shows the percentage of invocations which timed out over time. After an initial spike at 50%, it goes up and down ranging between 5% and 20% before dropping to 0%.]

In this example, you used the sum of the `calls_timed_out_total` and `calls_not_timed_out_total` metrics, rather than `invocations_total` metric. If the method is also annotated with the `@Retry` annotation, then each retry attempt would be considered its own timeout and would be counted towards either the `calls_timed_out_total` metric or the `calls_not_timed_out_total` metric.



=== See also:
* link:https://github.com/eclipse/microprofile-metrics[MicroProfile Metrics]
* link:https://download.eclipse.org/microprofile/microprofile-fault-tolerance-2.0.1/microprofile-fault-tolerance-spec.pdf[MicroProfile Fault Tolerance]
* link:/docs/ref/general/#microservice_observability_metrics.html[Microservice observability with metrics]
* Guide: link:/guides/microprofile-metrics.html[Providing metrics from a microservice]
